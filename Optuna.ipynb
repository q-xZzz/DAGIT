{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport optuna\nfrom optuna.visualization import plot_optimization_history\nfrom optuna.visualization import plot_param_importances\nfrom sklearn.metrics import cross_val_score, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/data/train_essays.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.sparse import load_npz\nX_train = load_npz('/data/processed_train.npz')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train['label'].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold = StratifiedKFold(n_splits=5, shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\ndef objective(trial):\n    n_estimators = trial.suggest_int('n_estimators', 100, 2000)\n    learning_rate = trial.suggest_float('learning_rate', 0.001, 1)\n    subsample = trial.suggest_float('subsample', 0.1, 1.0)\n    colsample_bytree = trial.suggest_float('colsample_bytree', 0.1, 1.0)\n    colsample_bylevel = trial.suggest_float('colsample_bylevel', 0.1, 1.0)\n    reg_alpha = trial.suggest_float('reg_alpha', 0.0, 1.0)\n    reg_lambda = trial.suggest_float('reg_lambda', 0.0, 1.0)\n    \n    xgb = XGBClassifier(n_estimators=n_estimators,\n                        learning_rate=learning_rate,\n                        subsample=subsample,\n                        colsample_bytree=colsample_bytree,\n                        colsample_bylevel=colsample_bylevel,\n                        use_label_encoder=False,\n                        reg_alpha=reg_alpha,\n                        reg_lambda=reg_lambda,\n                        random_state=42) \n    \n    score = cross_val_score(xgb, X_train, y_train, cv=kfold, scoring='roc_auc', n_jobs=-1).mean()\n    return score\n\n\nxgb_study = optuna.create_study(direction='maximize')\nxgb_study.optimize(objective, n_trials=100)\n\nplotly_config = {\"staticPlot\": True}\nfig = plot_optimization_history(xgb_study)\nfig.show(config=plotly_config)\n\nxgb_best_params = xgb_study.best_params\nxgb_best_score = xgb_study.best_value\n\nprint('Xgboost Best score:', xgb_best_score)\nprint('Xgboost Best parameters:', xgb_best_params)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\ndef objective(trial):\n    max_iter = trial.suggest_int('max_iter', 500, 10000)\n    alpha = trial.suggest_float('alpha', 1e-4, 10)  \n    ridge = Ridge(solver='sag', max_iter=max_iter, tol=1e-4, alpha=alpha)\n    score = cross_val_score(ridge, X_train, y_train, cv=kfold, scoring='roc_auc', n_jobs=-1).mean()\n    return score\n\nridge_study = optuna.create_study(direction='maximize')\nridge_study.optimize(objective, n_trials=100)  \n\nplotly_config = {\"staticPlot\": True}\nfig = plot_optimization_history(ridge_study)\nfig.show(config=plotly_config)\n\nridge_best_params = ridge_study.best_params\nridge_best_score = ridge_study.best_value\n\nprint('Ridge Best score:', ridge_best_score)\nprint('Ridge Best parameters:', ridge_best_params)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\ndef objective(trial):\n    alpha = trial.suggest_float('alpha', 1e-5, 1)  \n    mnb = MultinomialNB(alpha=alpha)\n    score = cross_val_score(mnb, X_train, y_train, cv=kfold, scoring='roc_auc', n_jobs=-1).mean()\n    return score\n\nmnb_study = optuna.create_study(direction='maximize')\nmnb_study.optimize(objective, n_trials=100)  \n\nplotly_config = {\"staticPlot\": True}\nfig = plot_optimization_history(mnb_study)\nfig.show(config=plotly_config)\n\nmnb_best_params = mnb_study.best_params\nmnb_best_score = mnb_study.best_value\n\nprint('MNB Best score:', mnb_best_score)\nprint('MNB Best parameters:', mnb_best_params)","metadata":{},"execution_count":null,"outputs":[]}]}